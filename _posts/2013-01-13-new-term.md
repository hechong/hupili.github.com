---
layout: post
title: "人人网小黄鸡"
description: "一月将过一半，新学期明天开始，今年至现在，经历过的最有趣的莫过于小黄鸡这个项目了。收获颇多，记之。"
category: 
tags: ["小黄鸡", "人人", "simsimi"]
---
{% include JB/setup %}

没听说的同学去[小黄鸡主页](http://page.renren.com/601621937)
看看就知道了。
还有[Github repo](https://github.com/wong2/xiaohuangji/)。
刚看到的时候感觉很有趣，
也和同学讨论了一下。
其实背后的AI对我并不是个太大的问题，
坊间早也流传各种分析，估计是用的simsimi；
即便没有simsimi，类似的智能机器人项目也有很多了。
而小黄鸡如何与人人接口，
才是我最感兴趣的。
因为一直在慢慢地做[snsapi](https://github.com/hupili/snsapi/)，
深知接口是一件很不容易的事情。
特别是小黄鸡每天处理这么大量的请求，
非常好奇它是怎么突破API限制的。
根据[人人API Quota](http://wiki.dev.renren.com/wiki/API_Quota)，
最高级别的授权，也不过是每小时900次获取信息，
那么最小的粒度即为4秒。
而小黄鸡很多时候是秒回，所以一定走了其他渠道。
之前总觉得抓包，分析页面请求，解析页面是件很麻烦的事情，从来没有像样地动手实践过。
随着小黄鸡的开源，各种疑惑都解开了。
看到消息后，立马暂停了其他的工作。
先读了`renren.py`，发现这正是我一直在找的，于是决定这几天先跟一下这个项目，学习学习。
一是学技术，二是学开源合作。
说来惭愧，这么大个人了，还没像样地参与过一个开源项目。
之前的[snsapi](https://github.com/hupili/snsapi/)，
只有两个同学在里面，处理过一个来自网络的pull requet。
虽然从形式上说，是开源的，但是开源合作的味道并为好生尝过。

从9号到13号，投入了4天半在小黄鸡和相关项目上，收获颇多。
开学后重心会移回research，学习也更倾向于数学，
开发和技术积累应该会慢慢变少。
值得记一下这几天的收获和一些positioning view。

## 技术

   * 最初看小黄鸡人人接口和simsimi接口的代码，
   知道了Python的`requests`。
   比`httplib`强大，特别是`Session`，
   自动维护cookie和keepalive，用起来超方便。
   * 阅读了9号的`renren.py`之后，
   发现直接从页面请求json数据也不是一件难事。
   可以说，最重要的是从这个文件得到了信心吧。
   正好，人人登录在香港总是出现验证码，
   这个是原接口中没有解决的，
   如果不解决的话，后面的功能都无从测试。
   于是自己来研究一下，用httpfox抓包，看请求流程，
   然后尝试下载验证码到本地供手动输入。
   * 为了验证同样方法用在snsapi里面的可能性，
   添加了`home_timeline`和`update`两个函数，
   之后就和snsapi完全兼容了。
   使用这个模式，不用再恼火api的quota，以及授权的问题。
   坏处是页面的变动肯定比api更频繁，
   需要的维护力度也更大。
   这块更新写得很随意，只是临时拼凑起功能，
   于是没有发pull到原项目，
   感兴趣的同学可以看
   [这里](https://github.com/hupili/xiaohuangji/blob/hushuo/renren.py)。
   * 基于升级后的人人接口，
   做了[hushuo](https://github.com/hupili/xiaohuangji/tree/hushuo)
   这一个分支。
   代码乱但是可以跑……
   在人人上跑了一天，看到感兴趣的人就回复，
   有at或者re，也去回复。
   后端还是simsimi，只不过比小黄鸡来说，拓展了信息渠道。
   （话说稍微一改就变成抢沙发利器了）
   * 感觉这种模式很有前途（后面有述），
   10号到11号盘算了怎么做一个垂直服务，比如新闻索引，先试试水。
   正好看到有人在微博上分享
   [新浪2012的新闻语料](http://zhangkaixu.github.com/resources.html)，
   就准备用它试试。
   * 解压后的语料大概有1G+，其实也不算大。
   学了下用`BeautifulSoup`做XML的解析。
   然后就是分词、做倒排，准备尝试一下使用redis来存索引。
   先单进程跑了一下，速度比较慢，感觉会跑很久去了。
   正好小黄鸡用了`rq`，于是也学着用rq来分配任务。
   结果是，提交任务的模块迅速跑完
   （扫1G的XML，一个文章一个job）；
   rqworker后来跑了一个晚上还没跑完
   （总25W，第二天还剩15W），
   还把服务器搞得很慢，连ssh登录都卡，副作用足了……
   初步猜测，可能的原因有：
   1、redis已经吃掉8G内存，硬盘交换严重；
   2、redis设置的是每秒fsync，可能太频繁，至于怎么优化redis配置，还没学过；
   3、rq有频繁的删除操作，
   当redis负载小的时候，比如全在内存里，删除是比较迅速的，
   但是当负载大的时候，删除导致更多硬盘交互，
   不仅rqworker卡死（很久拿不到任务），
   整个系统都很卡（cd进个目录都等半天）。
   最后盘算下来，还不如就单进程地跑，一晚上也跑完了，囧……
   之前也只用过Hadoop处理大的任务，
   轻量级并发方面，
   转入Python之前尝试用perl写过一套多进程多机器的
   [LWT](https://github.com/hupili/Lightweight-Distributing-Toolset)。
   用LWT做爬虫实用可以，挂200台机器还好；
   也试过多机并发跑仿真。
   对于这种单机上计算和IO都密集的任务，还没很好地尝试。
   基于这次的亏，之后可以考虑这些点：
   1、多进程；
   2、一进程多job，而不是一进程一job，
   以节省词典IO的overhead；
   3、使用memdisk来hold住词典等频繁读取的资源。
   重要的是分析清楚应用环境，
   感觉rq用于收支接近平衡并且worker的IO量不大的环境中更合适。
   * 12号看到项目发展地很快，dependency越来越多，
   觉得分头改跟不上进度，于是放弃继续单独做垂直Q/A；
   另外，即使做了，之后也没有时间维护。
   作罢，不过我依然觉得这是有前途的。
   * 12号看到wong2的
   [userscripts](https://github.com/wong2/userscripts)，
   感觉很有意思。
   看来从人人能拿到的信息还是挺多的。
   不过暗网抓取一直是学术圈的弱项，
   很多能操作的技术牛人后来也没在读研，
   所以这类数据其实很有价值。
   想起自己之前也写过些简单的，
   比如
   [学校论坛](http://bbs.qshpan.com/)
   的内外网转换，
   也翻出来[放在了github上](https://github.com/hupili/userscripts)。
   受了点启发，于是做了一个类似“我要当学霸”那个app的
   GreaseMonkey脚本，
   [说明见此](https://github.com/hupili/userscripts/blob/master/doc/stop-time-leecher.md)。
   期间在Firefox的ScratchPad上调试了不少时间。
   发现用JS来操作DOM完成一些工作挺有意思的。
   顺便记两个好项目：
   1、[Phantomjs](https://github.com/ariya/phantomjs/)，
   是一个headless browser，可以完美执行JS；
   2、[Brython](http://www.brython.info/index_en.html)，
   是JS写的Python2JS转换器，直接在浏览器执行。
   有了这两个工具，操作页面元素应该会很方便。
   * 11号到12号之间，simsimi对请求加了一些验证，
   于是原来的`simsimi.py`只能说一句话，
   第二句话即会收到错误信息。
   开始猜测是浏览器参数的问题，
   尝试把真实抓包到的参数都加进去没有解决。
   后来发现可能是keepalive的关系，
   于是用`requests.Session`搞定。
   * 小黄鸡的plugin机制还是比较成熟了，
   13号也有同学加了nosetest进去。
   话说nosetest我也没用过，就顺便写了个计算鸡的plugin，
   用下nosetest，感觉这样组织起来确实有章法。
   虽然表达式解析的逻辑没什么好说的，都是调用现成的库，
   怎么限制计算时间倒成了个问题。
   刚开始想用thread，网上也有很多错误建议用thread的，都不work。
   后来才知道Python的thread不支持kill，
   找到一个用process的解决方案，
   封装得很好，
   而且decorator的方式，使用起来很简洁。
   见
   [代码](http://code.activestate.com/recipes/577853-timeout-decorator-with-multiprocessing/)。
   * 另外，在fqj1994的提示下，知道了`sympy`，看起来很强大，
   加到了计算鸡的模块中。
   也是在fqj1994的提示下，知道了`doctest`，
   一看，真是个非常聪明的点子啊，把文档和测试用例完美合一。
   话说，看到这样的id，觉得自己好老……
   5年前的这会，我在干嘛呢？
   学校不让配电脑，平时就看书刷提搞成绩，偶尔通宵打个真三；
   没用过Linux，没用过Python，只用PASCAL写过点OI的题目，
   想起实用的任务就头疼。
   压力略大。

## 小黄鸡模式

其实小黄鸡给我的远不止如上的技术琐碎。
还没接触到项目的时候，就觉得这很有前途了。
有些看法：

### 入口

互联网的入口。
昨天看到Robin说
[互联网入口仍是搜索引擎](http://tech.sina.com.cn/i/2013-01-12/14387972767.shtml)。
相当不赞同。
虽然早几年前，大家都在闹腾说SNS取代搜索引擎成为入口，
但我们一直没有很好的案例。
尽管SNS的规模越来越大，数据越来越多，
在盈利方面总是无法和搜索引擎匹敌。
更重要的是，SNS解决的柔性需求，像打磨时间；
而搜索引擎解决的是刚性需求，像知识查找。
小黄鸡就是一个例子，告诉怎么在SNS上完成搜索引擎的功能。
其实很多用户的对话，已经是query的形式，
具体占比不知，表示对这份数据很感兴趣，
很希望能研究一下。
用户通过at或者回复一个帐号，来获得答案，
这个接口比在搜索引擎的框里面输入更自然。
有时候，思路要转换一下：

   * 还在厂中时，产品人员最津津乐道的一个案例就是
   baidu和hao123的关系了。
   最初，baidu是想方设法让hao123给它导流量，比如安个搜索框。
   当然，还有不少其他合作站点也安了搜索框。
   最后发现这样导来的流量不明显，相反，用户要的就是hao123。
   hub页其实本身就是一个强需求。
   于是当时的pm改变了思路，让baidu给hao123导去流量。
   最后发现后者更符合用户需求。
   * 我离厂前，所知的一个重点发展方向便是和新浪微博进行数据合作。
   当时的pm已经意识到，SNS上承载了最新的数据，
   baidu光用一些特殊的时效性库已经无法满足需求，
   所以很期待将新浪的数据导入百度。
   其实，完全可以反过来。
   用户在新浪上at百度的一个帐号问问题，百度在下面
   回复一些链接和摘要。
   作为知识性的问题，直接抽取知道或者百科的数据来回答。
   从最近的动作来看，百度在前端展现上是下了不少功夫，
   不过我感觉小黄鸡模式是更自然的接口。
   SNS对于新闻类需求可能满足得比较好，
   所以你在新浪上直接搜，和看百度的微博特殊库，
   应该是没有区别的。
   相反，百度可以满足的知识性需求是SNS所没有的。
   比如，前天微博上比较火的是伊能静。
   如果想知道更多关于事件本身的消息，直接在微博上搜就好了，
   出了被屏蔽的情况外，并无返回百度再搜的需求。
   而对于那些不关注娱乐圈的人，这时候可能会去百度，
   搜一下伊能静的身世。
   如果我能at一下百度，然后直接问“伊能静身世”，
   这样岂不是更自然？

所谓手机是互联网入口，不过在谈硬件罢了。
就好比几年前，大家说搜索引擎是入口的时候，
我说一句，我家那根以太网线才是我的入口一样。
这个对话明显是异面的。
又或者，我说一句，浏览器才是入口，瞬间又成废话了。
pc上也是用浏览器上网，手机上还是用浏览器。
看过诸多提法，我觉得“入口”的实体还是应该落到一种服务上，
而不是承载它的软件和硬件形式。

   * 搜索引擎作为入口的年代，
   它不仅满足了搜索知识的需求，
   还满足了很多附带需求，比如记网址。
   那个时候，我们干的事情是“上网--找一个网站--获取信息/娱乐”。
   * 而现在的SNS基本上已经把用户锁死。
   很多人只用在一个SNS上就能获取信息或者娱乐。
   这种服务形式就是入口：
   在网络的结构上，传递信息。
   类似的，搜索引擎可以认为是一个扁平的网络：
   搜索引擎是个核心节点，
   所有站点和所有用户都有一条连接到搜索引擎。

就目前来看，在SNS上对话是一种更自然的方式。
可以想象，你跑到百度去输入一个“给我推荐一部电影”，
这种感觉会多么奇怪。
而实测也表明，结果不怎么样。
相反，如果我“@小黄鸡，给我推荐部电影”，
这个操作就会显得相当自然。
小鸡推荐的结果，我的朋友也可以受益。
（当然，这个功能还没开发，估计之后会有吧，呵呵）

除了用户接口，小黄鸡的传播方式也更自然。
你的一个朋友at了小黄鸡，两个朋友也at了小黄鸡，
于是你自然会好奇地去试一下。
这么短时间，就积累了将近200W关注，很不容易啊，
根据人人的官方的数字，这就是1%的用户了。
光算活跃用户的话，估计就是10%了吧。
病毒传播的威力真心很大。
题外话，个人感觉在Linear Threashold和Independent Cascade
两个简单model中，实际情况更接近LT。
试想一下，百度第一次推出开放搜索接口的时候，你是怎么知道的？
（比如输入“163”，可以直接在当前页面登录网易邮箱）
可能是某次搜索无意看到，也可能是从广告上看到。
当产品有新feature的时候，怎么让用户接受也是个大问题。
而社交传播，小黄鸡让我们看到的是：使用即推广。
比如，今天你看到有同学在问小黄鸡天气了，
于是你也去试试，你以后在逛人人的时候或许也会想起去问小鸡天气。
对于传统产品，必须得用户使用之后并且觉得非常好，
才会主动像朋友推荐。
而在SNS上，使用即推广，新feature很容易传播。

### 项目远景

刚看到这个项目的时候，
我就觉得作者最终会获得人人和simsimi的正式API支持。
因为前几天都在跟进技术，没有时间写，现在来说有点马后炮了。
一款好作品，实际上是多方共赢的，
人人增加用户粘度，simsimi也获得推广，何不支持呢。

对于小黄鸡本身，后面可以做的也就是调整架构
（服务量）和改AI（服务多样性），
加入更多的垂直元素，直到某天你发现突然可以“@百度”为止。
不过我感觉百度动作没这么快，
第一个能at的估计是搜狗或者360吧，
先猜着，呵呵。

在小黄鸡之外，我觉得这种模式可以引发很多新颖的服务开发。
特别是`renren.py`从技术上提供的支持，是非常显著的。
可惜的是，随着人人官方支持，`renren.py`的开发已经不是主菜。
刚看到的时候，本有意将其单列个项目，
但是感觉会找不到人维护，于是作罢。
[snsapi](https://github.com/hupili/snsapi/)
目前走的是api，因为有那么多app都在用，
所以接口稳定，维护成本低。
小黄鸡这种页面接口，就是维护麻烦，
这是人人说改自己就可以立马改的。
一旦项目成了气候，就必须要专人维护，
才能“道”和“魔”平衡。
像我在
[hushuo](https://github.com/hupili/xiaohuangji/blob/hushuo/renren.py)
里面按照snsapi格式做的原型接口，
很容易就挂掉。

仔细想了下为什么snsapi不易推广，
主要问题还是走api的quota限制。
这使得你用snsapi开发个人服务还行，
譬如[snsrouter](https://github.com/hupili/sns-router)。
开发者可以自娱自乐，能从中得到便利。
普通用户要使用，也得经过一些部署，门槛陡然增加。
而另一方面，即使开发者有意部署一个服务给别人使用，
由于quota的限制，根本无法达到可用级别。
另外，用api随时面临被kill掉key的危险，
所以服务只能做最低假设，即利用测试状态的app。
这样一个key一天就200的quota，
可谓巧妇难为无米只炊啊。
snsapi下一个应扩展的插件，
就应该像
[hushuo](https://github.com/hupili/xiaohuangji/blob/hushuo/renren.py)
这样。
基于这个插件，可以写面向用户的服务，便于网络传播。
这样更容易让开发者看到其价值。


